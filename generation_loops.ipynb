{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamwagnerhoegh/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# For modules loading\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, T5ForConditionalGeneration\n",
    "import torch\n",
    "from itertools import cycle\n",
    "import os \n",
    "from transformers import pipeline\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# For BM25\n",
    "import src.bm25_IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading devset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set = pd.read_csv('output/devset/dev_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "      <th>pnumber</th>\n",
       "      <th>law number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hvad har ejeren af en ejerlejlighed, sammen me...</td>\n",
       "      <td>Grunden, fælles bestanddele og tilbehør.</td>\n",
       "      <td>Ejeren af en ejerlejlighed har sammen med andr...</td>\n",
       "      <td>3</td>\n",
       "      <td>LOV nr 908 af 18/06/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hvem fastsætter eller aftaler bestemmelser om ...</td>\n",
       "      <td>Finansministeren fastsætter eller aftaler best...</td>\n",
       "      <td>Højskolen skal følge de af finansministeren fa...</td>\n",
       "      <td>30</td>\n",
       "      <td>LBK nr 780 af 08/08/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hvad skal Beskæftigelsesministeriet og Finanst...</td>\n",
       "      <td>Den indsendte årsrapport skal i det mindste in...</td>\n",
       "      <td>Uden ugrundet ophold efter repræsentantskabets...</td>\n",
       "      <td>25 l</td>\n",
       "      <td>LBK nr 1110 af 10/10/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hvor mange procent må kapitalandele i og lån y...</td>\n",
       "      <td>Kapitalandele i og lån ydet til en virksomhed ...</td>\n",
       "      <td>Følgende grænser for Arbejdsmarkedets Tillægsp...</td>\n",
       "      <td>26 e</td>\n",
       "      <td>LBK nr 1110 af 10/10/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hvad er en betingelse for retten til jobpræmie?</td>\n",
       "      <td>Det er en betingelse for retten til jobpræmie ...</td>\n",
       "      <td>Det er en betingelse for retten til jobpræmie,...</td>\n",
       "      <td>9</td>\n",
       "      <td>LOV nr 287 af 29/03/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hvordan anføres kandidatlister på stemmesedler?</td>\n",
       "      <td>I særskilte felter.</td>\n",
       "      <td>Kandidatlisterne anføres på stemmesedlen i sær...</td>\n",
       "      <td>46</td>\n",
       "      <td>LBK nr 6 af 08/01/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Hvem iværksætter beslaglæggelse?</td>\n",
       "      <td>Politiet.</td>\n",
       "      <td>Politiet iværksætter beslaglæggelse. Politiet ...</td>\n",
       "      <td>807</td>\n",
       "      <td>LBK nr 250 af 04/03/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Hvis interesser skal foranstaltninger mod inte...</td>\n",
       "      <td>De forvaltede alternative investeringsfondes e...</td>\n",
       "      <td>En forvalter af alternative investeringsfonde ...</td>\n",
       "      <td>23</td>\n",
       "      <td>LBK nr 231 af 01/03/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Hvad skal valgstyrere eller tilforordnede vælg...</td>\n",
       "      <td>At stemmekasserne er tomme.</td>\n",
       "      <td>Afstemningen begynder kl. Inden stemmeafgivnin...</td>\n",
       "      <td>38</td>\n",
       "      <td>LBK nr 1432 af 01/12/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Hvem fastsætter om udenlandske afgørelser af b...</td>\n",
       "      <td>Justitsministeren.</td>\n",
       "      <td>Justitsministeren kan fastsætte bestemmelser, ...</td>\n",
       "      <td>223 a</td>\n",
       "      <td>LBK nr 250 af 04/03/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Hvad har ejeren af en ejerlejlighed, sammen me...   \n",
       "1    Hvem fastsætter eller aftaler bestemmelser om ...   \n",
       "2    Hvad skal Beskæftigelsesministeriet og Finanst...   \n",
       "3    Hvor mange procent må kapitalandele i og lån y...   \n",
       "4      Hvad er en betingelse for retten til jobpræmie?   \n",
       "..                                                 ...   \n",
       "98     Hvordan anføres kandidatlister på stemmesedler?   \n",
       "99                    Hvem iværksætter beslaglæggelse?   \n",
       "100  Hvis interesser skal foranstaltninger mod inte...   \n",
       "101  Hvad skal valgstyrere eller tilforordnede vælg...   \n",
       "102  Hvem fastsætter om udenlandske afgørelser af b...   \n",
       "\n",
       "                                                answer  \\\n",
       "0             Grunden, fælles bestanddele og tilbehør.   \n",
       "1    Finansministeren fastsætter eller aftaler best...   \n",
       "2    Den indsendte årsrapport skal i det mindste in...   \n",
       "3    Kapitalandele i og lån ydet til en virksomhed ...   \n",
       "4    Det er en betingelse for retten til jobpræmie ...   \n",
       "..                                                 ...   \n",
       "98                                 I særskilte felter.   \n",
       "99                                           Politiet.   \n",
       "100  De forvaltede alternative investeringsfondes e...   \n",
       "101                        At stemmekasserne er tomme.   \n",
       "102                                 Justitsministeren.   \n",
       "\n",
       "                                                  text pnumber  \\\n",
       "0    Ejeren af en ejerlejlighed har sammen med andr...       3   \n",
       "1    Højskolen skal følge de af finansministeren fa...      30   \n",
       "2    Uden ugrundet ophold efter repræsentantskabets...    25 l   \n",
       "3    Følgende grænser for Arbejdsmarkedets Tillægsp...    26 e   \n",
       "4    Det er en betingelse for retten til jobpræmie,...       9   \n",
       "..                                                 ...     ...   \n",
       "98   Kandidatlisterne anføres på stemmesedlen i sær...      46   \n",
       "99   Politiet iværksætter beslaglæggelse. Politiet ...     807   \n",
       "100  En forvalter af alternative investeringsfonde ...      23   \n",
       "101  Afstemningen begynder kl. Inden stemmeafgivnin...      38   \n",
       "102  Justitsministeren kan fastsætte bestemmelser, ...   223 a   \n",
       "\n",
       "                    law number  \n",
       "0     LOV nr 908 af 18/06/2020  \n",
       "1     LBK nr 780 af 08/08/2019  \n",
       "2    LBK nr 1110 af 10/10/2014  \n",
       "3    LBK nr 1110 af 10/10/2014  \n",
       "4     LOV nr 287 af 29/03/2017  \n",
       "..                         ...  \n",
       "98      LBK nr 6 af 08/01/2024  \n",
       "99    LBK nr 250 af 04/03/2024  \n",
       "100   LBK nr 231 af 01/03/2024  \n",
       "101  LBK nr 1432 af 01/12/2023  \n",
       "102   LBK nr 250 af 04/03/2024  \n",
       "\n",
       "[103 rows x 5 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KennethTM/gpt-neo-1.3B-danish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "MODEL_NAME = \"KennethTM/gpt-neo-1.3B-danish\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Set the device\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\" # set up for mac here, change to cuda if needed\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_answers_tf_idf_k1 = []\n",
    "# evaluating tf-idf\n",
    "for question, documents in tqdm(zip(dev_set['question'], dev_set['tf_idf_k1']), desc='Answering questions'):\n",
    "\n",
    "    # assemble a prompt from the documents, question and prompting an answer\n",
    "    prompt = f\"Relevante paragraffer: {documents} Spørgsmål: {question} \\nIndsæt svar her baseret på de relevante paragraffer:\"\n",
    "\n",
    "    # tokenize\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
    "\n",
    "    max_length = len(input_ids[0]) + 100\n",
    "\n",
    "    # generate an answer within torch.no_grad() to save compute\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            # generation set to stop at '.' as it otherwise just repeats itself (think it's because we don't sample)\n",
    "            eos_token_id=tokenizer.encode(' Spørgsmål')[0]\n",
    "        )\n",
    "\n",
    "    # decode generated answer\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True).strip(' Spørgsmål')\n",
    "\n",
    "    # append answer to list\n",
    "    neo_answers_tf_idf_k1.append(answer[len(prompt):].strip())  # strip the prompt to leave just the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### strombergnlp/dant5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamwagnerhoegh/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pretrained T5 model and tokenizer\n",
    "model_name = \"strombergnlp/dant5-large\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\" # set up for mac here, change to cuda if needed\n",
    "model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevante paragraffer: En videoafhøring efter § 340 a eller § 155, stk. 3, kan anvendes som bevis under hovedforhandlingen.\n",
      "Spørgsmål: Har en person, der er blevet videoafhørt pligt til at afgive forklaring som vidne under hovedforhandlingen?\n",
      "Indsæt svar her baseret på de relevante paragraffer: \n",
      "\n",
      ". Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja. Svar: Ja.\n"
     ]
    }
   ],
   "source": [
    "#for question, documents in tqdm(zip(dev_set['question, str'], dev_set['tf_idf_k1']), desc='Answering questions'):\n",
    "\n",
    "# Example question and context\n",
    "\n",
    "idx = 10\n",
    "\n",
    "question = dev_set.loc[idx, 'question']\n",
    "documents = dev_set.loc[idx, 'dense_cls_k1']\n",
    "\n",
    "# Format the input for T5\n",
    "input_text = f\"Relevante paragraffer: {documents}\\nSpørgsmål: {question}\\nIndsæt svar her baseret på de relevante paragraffer:\"\n",
    "\n",
    "# Tokenize the input and generate an answer\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
    "\n",
    "max_length = len(input_ids[0]) + 100\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        # generation set to stop at ' Spørgsmål' as it otherwise just repeats itself (think it's because we don't sample)\n",
    "        eos_token_id=tokenizer.encode(' Spørgsmål')[0]\n",
    "    )\n",
    "\n",
    "# Decode and print the generated answer\n",
    "answer = tokenizer.decode(outputs[0], skip_special_tokens=True).strip(' Spørgsmål')\n",
    "print(input_text, '\\n')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Børne- og undervisningsministeren.'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set.loc[76, 'answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tjek idx 10\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
