{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamwagnerhoegh/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate retrieval corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1637/1637 [00:00<00:00, 10264.94it/s]\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/adamwagnerhoegh/Documents/Legal data/domsdatabasen.retsinformation_newer.json'\n",
    "\n",
    "with open(path) as f:\n",
    "    retsinfo = json.load(f)\n",
    "\n",
    "rag_list = []\n",
    "idx = 0\n",
    "for lov in tqdm(retsinfo):\n",
    "    for kapitel in lov['kapitler']:\n",
    "        lov_navn = lov['shortName']\n",
    "        for paragraffer in kapitel['paragraffer']:\n",
    "            temp_paragraf_dict = {}\n",
    "            temp_paragraf_dict['paragraf_nr'] = paragraffer['nummer']\n",
    "            temp_paragraf_dict['lovnavn'] = lov_navn\n",
    "            temp_paragraf_list = []\n",
    "            for styk in paragraffer['stk']:\n",
    "                temp_paragraf_list.append(styk['tekst'])\n",
    "            temp_paragraf_dict['text'] = ' '.join(temp_paragraf_list)\n",
    "            rag_list.append(temp_paragraf_dict)\n",
    "\n",
    "with open(\"rag_list.txt\", \"w\") as file:\n",
    "    for item in rag_list:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question, str</th>\n",
       "      <th>answer, str</th>\n",
       "      <th>text, str</th>\n",
       "      <th>pnumber, str</th>\n",
       "      <th>law number, str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hvad har ejeren af en ejerlejlighed, sammen me...</td>\n",
       "      <td>Grunden, fælles bestanddele og tilbehør</td>\n",
       "      <td>'Ejeren af en ejerlejlighed har sammen med and...</td>\n",
       "      <td>3</td>\n",
       "      <td>LOV nr 908 af 18/06/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hvem fastsætter eller aftaler bestemmelser om ...</td>\n",
       "      <td>Finansministeren fastsætter eller aftaler best...</td>\n",
       "      <td>'Højskolen skal følge de af finansministeren f...</td>\n",
       "      <td>30</td>\n",
       "      <td>LBK nr 780 af 08/08/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hvad skal Beskæftigelsesministeriet og Finanst...</td>\n",
       "      <td>Den indsendte årsrapport skal i det mindste in...</td>\n",
       "      <td>'Uden ugrundet ophold efter repræsentantskabet...</td>\n",
       "      <td>25 l</td>\n",
       "      <td>LBK nr 1110 af 10/10/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hvor mange procent må kapitalandele i og lån y...</td>\n",
       "      <td>Kapitalandele i og lån ydet til en virksomhed ...</td>\n",
       "      <td>'Følgende grænser for Arbejdsmarkedets Tillægs...</td>\n",
       "      <td>26 e</td>\n",
       "      <td>LBK nr 1110 af 10/10/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hvad er en betingelse for retten til jobpræmie?</td>\n",
       "      <td>Det er en betingelse for retten til jobpræmie ...</td>\n",
       "      <td>'Det er en betingelse for retten til jobpræmie...</td>\n",
       "      <td>9</td>\n",
       "      <td>LOV nr 287 af 29/03/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Hvordan anføres kandidatlister på stemmesedler?</td>\n",
       "      <td>I særskilte felter.</td>\n",
       "      <td>Kandidatlisterne anføres på stemmesedlen i sær...</td>\n",
       "      <td>46</td>\n",
       "      <td>LBK nr 6 af 08/01/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Hvem iværksætter beslaglæggelse?</td>\n",
       "      <td>Politiet.</td>\n",
       "      <td>Politiet iværksætter beslaglæggelse. Politiet ...</td>\n",
       "      <td>807</td>\n",
       "      <td>LBK nr 250 af 04/03/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Hvis interesser skal foranstaltninger mod inte...</td>\n",
       "      <td>De forvaltede alternative investeringsfondes e...</td>\n",
       "      <td>En forvalter af alternative investeringsfonde ...</td>\n",
       "      <td>23</td>\n",
       "      <td>LBK nr 231 af 01/03/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Hvad skal valgstyrere eller tilforordnede vælg...</td>\n",
       "      <td>At stemmekasserne er tomme.</td>\n",
       "      <td>Afstemningen begynder kl. Inden stemmeafgivnin...</td>\n",
       "      <td>38</td>\n",
       "      <td>LBK nr 1432 af 01/12/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Hvem fastsætter om udenlandske afgørelser af b...</td>\n",
       "      <td>Justitsministeren.</td>\n",
       "      <td>Justitsministeren kan fastsætte bestemmelser, ...</td>\n",
       "      <td>223 a</td>\n",
       "      <td>LBK nr 250 af 04/03/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question, str  \\\n",
       "0    Hvad har ejeren af en ejerlejlighed, sammen me...   \n",
       "1    Hvem fastsætter eller aftaler bestemmelser om ...   \n",
       "2    Hvad skal Beskæftigelsesministeriet og Finanst...   \n",
       "3    Hvor mange procent må kapitalandele i og lån y...   \n",
       "4      Hvad er en betingelse for retten til jobpræmie?   \n",
       "..                                                 ...   \n",
       "101    Hvordan anføres kandidatlister på stemmesedler?   \n",
       "102                   Hvem iværksætter beslaglæggelse?   \n",
       "103  Hvis interesser skal foranstaltninger mod inte...   \n",
       "104  Hvad skal valgstyrere eller tilforordnede vælg...   \n",
       "105  Hvem fastsætter om udenlandske afgørelser af b...   \n",
       "\n",
       "                                           answer, str  \\\n",
       "0              Grunden, fælles bestanddele og tilbehør   \n",
       "1    Finansministeren fastsætter eller aftaler best...   \n",
       "2    Den indsendte årsrapport skal i det mindste in...   \n",
       "3    Kapitalandele i og lån ydet til en virksomhed ...   \n",
       "4    Det er en betingelse for retten til jobpræmie ...   \n",
       "..                                                 ...   \n",
       "101                                I særskilte felter.   \n",
       "102                                          Politiet.   \n",
       "103  De forvaltede alternative investeringsfondes e...   \n",
       "104                        At stemmekasserne er tomme.   \n",
       "105                                 Justitsministeren.   \n",
       "\n",
       "                                             text, str pnumber, str  \\\n",
       "0    'Ejeren af en ejerlejlighed har sammen med and...            3   \n",
       "1    'Højskolen skal følge de af finansministeren f...           30   \n",
       "2    'Uden ugrundet ophold efter repræsentantskabet...         25 l   \n",
       "3    'Følgende grænser for Arbejdsmarkedets Tillægs...         26 e   \n",
       "4    'Det er en betingelse for retten til jobpræmie...            9   \n",
       "..                                                 ...          ...   \n",
       "101  Kandidatlisterne anføres på stemmesedlen i sær...           46   \n",
       "102  Politiet iværksætter beslaglæggelse. Politiet ...          807   \n",
       "103  En forvalter af alternative investeringsfonde ...           23   \n",
       "104  Afstemningen begynder kl. Inden stemmeafgivnin...           38   \n",
       "105  Justitsministeren kan fastsætte bestemmelser, ...        223 a   \n",
       "\n",
       "               law number, str  \n",
       "0     LOV nr 908 af 18/06/2020  \n",
       "1     LBK nr 780 af 08/08/2019  \n",
       "2    LBK nr 1110 af 10/10/2014  \n",
       "3    LBK nr 1110 af 10/10/2014  \n",
       "4     LOV nr 287 af 29/03/2017  \n",
       "..                         ...  \n",
       "101     LBK nr 6 af 08/01/2024  \n",
       "102   LBK nr 250 af 04/03/2024  \n",
       "103   LBK nr 231 af 01/03/2024  \n",
       "104  LBK nr 1432 af 01/12/2023  \n",
       "105   LBK nr 250 af 04/03/2024  \n",
       "\n",
       "[106 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load excel files in dev set folder\n",
    "import os\n",
    "\n",
    "dev_set_folder = \"devset\"\n",
    "\n",
    "dfs = []\n",
    "for file in os.listdir(dev_set_folder):\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        df = pd.read_excel(os.path.join(dev_set_folder, file))\n",
    "        dfs.append(df)\n",
    "\n",
    "# merge all excel\n",
    "dev_set = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# add csv\n",
    "rag_batch_1_with_qa = pd.read_csv(\"devset/rag_batch_1_with_qa.csv\", sep=\";\").iloc[:, 1:].dropna()\n",
    "rag_batch_1_with_qa.columns = dev_set.columns\n",
    "dev_set = pd.concat([dev_set, rag_batch_1_with_qa], ignore_index=True)\n",
    "\n",
    "dev_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize retrieval corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42593/42593 [00:00<00:00, 117957.46it/s]\n"
     ]
    }
   ],
   "source": [
    "rag_list2 = rag_list\n",
    "\n",
    "def preprocess(rag_list):\n",
    "    # extract and preprocess text\n",
    "    corpus = [item['text'] for item in rag_list]\n",
    "    corpus = [re.sub('\\\\s{2,}', ' ', \n",
    "                     re.sub('\\\\W|[0-9]|§', ' ',\n",
    "                           item.lower())) for item in corpus]\n",
    "\n",
    "    # remove stopwords\n",
    "    #nltk.download('punkt')\n",
    "    stop_words = set(stopwords.words('danish'))\n",
    "    corpus = [' '.join(word for word in text.split() \n",
    "                      if word not in stop_words) for text in tqdm(corpus)]\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "corpus = preprocess(rag_list2)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE LATER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse retrieval pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hvor længe kan der gives tilladelse til afholdelse af lokale puljevæddemål på cykelløb på bane, hundevæddeløb på væddeløbsbane, kapflyvning med duer og hestevæddeløb? \n",
      "\n",
      "§ 25.: Tilladelse til udbud og arrangering af spil kan gives til personer og selskaber m.v. (juridiske personer), medmindre andet fremgår af denne lov, jf. dog stk. 2. Tilladelse til udbud og arrangering af lokale puljevæddemål på cykelløb på bane, hundevæddeløb på væddeløbsbane og kapflyvning med duer, jf. § 13, kan kun gives til selskaber m.v. (juridiske personer), der er arrangør af cykelløb på bane, hundevæddeløb på væddeløbsbaner eller kapflyvning med duer, og som er tilsluttet den pågældende sportsgrens centralorganisation eller -forbund.\n",
      "§ 13.: Der kan gives tilladelse til afholdelse af lokale puljevæddemål på cykelløb på bane, hundevæddeløb på væddeløbsbane, kapflyvning med duer og hestevæddeløb. Tilladelse kan gives for indtil 3 år og for et bestemt antal dage for de enkelte år. Når begivenheden, der indgås væddemål på, finder sted på en afgrænset bane, må indsatsen i væddemålet kun ske inden for banens område og i direkte tilknytning til begivenheden.\n",
      "§ 9.: Der kan gives tilladelse til afholdelse af lokale puljevæddemål på cykelløb på bane, hundevæddeløb på væddeløbsbane, kapflyvning med duer og hestevæddeløb. Tilladelse efter stk. 1 kan gives for indtil 3 år og for et bestemt antal dage for de enkelte år. Når begivenheden, der indgås væddemål på, finder sted på en afgrænset bane, må indsatsen i væddemålet kun ske inden for banens område og i direkte tilknytning til begivenheden. Tilladelse kan kun gives til selskaber m.v. (juridiske personer), der er arrangør af cykelløb på bane, hundevæddeløb på væddeløbsbane eller kapflyvning med duer, og som er tilknyttet den pågældende sportsgrens centralorganisation eller forbund.\n"
     ]
    }
   ],
   "source": [
    "def sparse_retrieval(question, sparse_matrix, k=3):\n",
    "    \"\"\"\n",
    "    Function that takes a question and returns a list of paragraphs that are most relevant to the question\n",
    "    \"\"\"\n",
    "\n",
    "    # preprocess and vectorize question\n",
    "    question_processed = [re.sub('\\\\s{2,}', ' ', \n",
    "                               re.sub('\\\\W|[0-9]|§', ' ',\n",
    "                                     question.lower()))]\n",
    "    \n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words('danish'))\n",
    "    question_processed = [' '.join(word for word in text.split() \n",
    "                                 if word not in stop_words) for text in question_processed]\n",
    "    \n",
    "    question_vector = vectorizer.transform(question_processed)\n",
    "\n",
    "    # sparse retrieval (cosine similarity)\n",
    "    sparse_retrieval = X.dot(question_vector.T).toarray()\n",
    "\n",
    "    # get top k paragraphs\n",
    "    top_k = np.argsort(sparse_retrieval.flatten())[-k:]\n",
    "\n",
    "    return top_k\n",
    "\n",
    "# check if it works using a random question from the dev set\n",
    "random_question = dev_set.iloc[np.random.randint(0, len(dev_set))]['question, str']\n",
    "print(random_question, '\\n')\n",
    "top_k = sparse_retrieval(random_question, X)\n",
    "for i in top_k:\n",
    "    print(f'{rag_list2[i][\"paragraf_nr\"]}: {rag_list2[i][\"text\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embedding corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating embedding corpus with the 'KennethTM/bert-base-uncased-danish'\n",
    "\n",
    "# bert_tokenizer = AutoTokenizer.from_pretrained(\"KennethTM/bert-base-uncased-danish\")\n",
    "# bert_model = AutoModel.from_pretrained(\"KennethTM/bert-base-uncased-danish\")\n",
    "\n",
    "# device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# cls_embeddings = []\n",
    "\n",
    "# idx = 0\n",
    "\n",
    "# for item in tqdm(rag_list):\n",
    "#     # doing a try and except as some paragraphs may exceed the context window of the BERT (I believe)\n",
    "#     try:\n",
    "#         # tokenize texts\n",
    "#         input_ids = bert_tokenizer.encode(item['text'], return_tensors='pt')\n",
    "#         # run through BERT\n",
    "#         with torch.no_grad():  # disable gradient computation for inference\n",
    "#             outputs = bert_model(input_ids)\n",
    "#         # extract cls-token\n",
    "#         cls_vector = outputs.last_hidden_state[:, 0, :]\n",
    "#         # add cls-vector to list of embeddings\n",
    "#         cls_embeddings.append(cls_vector)\n",
    "#     except:\n",
    "#         # if error then count errors with this\n",
    "#         idx += 1\n",
    "\n",
    "# print(f'{idx} no. of errors')\n",
    "\n",
    "# # concatenate list into torch tensor\n",
    "# cls_embeddings_tensor = torch.cat(cls_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the tensor\n",
    "#torch.save(cls_embeddings_tensor, '/Users/adamwagnerhoegh/Documents/SODAS/sem3/nlp_itu/cls_embeddings_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tensor\n",
    "\n",
    "# cls_embeddings_tensor = torch.load('/Users/adamwagnerhoegh/Documents/SODAS/sem3/nlp_itu/cls_embeddings_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating embedding corpus with the 'vesteinn/DanskBERT'\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"vesteinn/DanskBERT\")\n",
    "# model = AutoModel.from_pretrained(\"vesteinn/DanskBERT\")\n",
    "\n",
    "# device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# cls_embeddings = []\n",
    "\n",
    "# idx = 0\n",
    "\n",
    "# for item in tqdm(rag_list):\n",
    "#     # doing a try and except as some paragraphs may exceed the context window of the BERT (I believe)\n",
    "#     try:\n",
    "#         # tokenize texts\n",
    "#         input_ids = tokenizer.encode(item['text'], return_tensors='pt')\n",
    "#         # run through BERT\n",
    "#         with torch.no_grad():  # disable gradient computation for inference\n",
    "#             outputs = model(input_ids)\n",
    "#         # extract cls-token\n",
    "#         cls_vector = outputs.last_hidden_state[:, 0, :]\n",
    "#         # add cls-vector to list of embeddings\n",
    "#         cls_embeddings.append(cls_vector)\n",
    "#     except:\n",
    "#         # if error then count errors with this\n",
    "#         idx += 1\n",
    "\n",
    "# print(f'{idx} no. of errors')\n",
    "\n",
    "# # concatenate list into torch tensor\n",
    "# cls_embeddings_tensor_DanskBERT = torch.cat(cls_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DanskBERT-tensor\n",
    "#torch.save(cls_embeddings_tensor_DanskBERT, '/Users/adamwagnerhoegh/Documents/SODAS/sem3/nlp_itu/cls_embeddings_DanskBERT.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the DanskBERT-tensor\n",
    "#cls_embeddings_tensor_DanskBERT = torch.load('/Users/adamwagnerhoegh/Documents/SODAS/sem3/nlp_itu/cls_embeddings_DanskBERT.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense retrieval pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamwagnerhoegh/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at vesteinn/DanskBERT and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"vesteinn/DanskBERT\")\n",
    "bert_model = AutoModel.from_pretrained(\"vesteinn/DanskBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedriftværn, der er etableret i henhold til den lovgivning, der er gældende indtil 1. januar 1993, opretholdes, medmindre at hvad? \n",
      "\n",
      "Inden der indgås aftale om køb af en pakkerejse, skal den rejsende gives følgende oplysninger, hvis det er relevant for pakkerejsen, herunder om rejseydelsernes væsentligste kendetegn: Rejsedestination, rejserute, varigheden af og tidspunktet for opholdet og, hvis indkvartering er inkluderet, antallet af inkluderede overnatninger, Rejsedestination, rejserute, varigheden af og tidspunktet for opholdet og, hvis indkvartering er inkluderet, antallet af inkluderede overnatninger, anvendte befordringsmidler og deres kendetegn og kategori, sted, dato og tidspunkt for af- og hjemrejse og oplysninger om steder, hvor der gøres ophold undervejs, med angivelse af disse opholds varighed og transportforbindelser, indkvarteringsstedets beliggenhed, væsentligste kendetegn og kategori i henhold til destinationslandets regler, inkluderede måltider, besøg, udflugter eller andre ydelser, der er inkluderet i pakkerejsens samlede pris, hvorvidt nogen af rejseydelserne leveres til den rejsende som del af en gruppe, hvis det ikke fremgår af sammenhængen, og hvis muligt, gruppens størrelse, hvis den rejsendes nytte af andre turistydelser afhænger af en effektiv mundtlig kommunikation, oplyses det sprog, som disse ydelser vil foregå på, om rejsen generelt er egnet for bevægelseshæmmede personer og på den rejsendes anmodning præcise oplysninger om rejsens egnethed under hensyn til den rejsendes behov, rejsearrangørens og i givet fald formidlerens firmanavn, adresse, telefonnummer og e-mailadresse, hvis den erhvervsdrivende har en sådan, den samlede pris for pakkerejsen inklusive skatter, afgifter og alle yderligere gebyrer og omkostninger eller eventuelt, hvilke typer yderligere omkostninger den rejsende typisk vil kunne forvente at skulle betale, betalingsvilkårene for rejsen, det mindste antal personer, der kræves, for at pakkerejsen gennemføres, og den frist, som gælder for rejsearrangørens opsigelse af pakkerejsen, hvis minimumsantallet ikke er nået, jf. § 20, stk. 1, generelle oplysninger om pas- og visumkrav og oplysninger om sundhedsmæssige formaliteter i de‌sti‌na‌ti‌‌onslandet, den rejsendes afbestillingsret efter § 15, stk. 1, og muligheden for eller forpligtelsen til tegning af en forsikring, der dækker den rejsendes udgifter ved opsigelsen af aftalen eller udgifter til bistand, herunder til hjemtransport i tilfælde af ulykke, sygdom eller død. Den rejsende skal sammen med de oplysninger, der er nævnt i stk. 1, gives de standardoplysninger, der er nævnt i bilag 1, del A og B, ved brug af skemaerne i bilag 1, del A og B. Forbrugeraftalelovens § 8, stk. 3, og § 12 finder anvendelse på pakkerejser, som sælges eller udbydes til rejsende.\n",
      "Arresten kan kræves ophævet af fogeden, hvis kreditor undlader at anlægge arrestsag eller sag vedrørende kravet inden de i § 683 nævnte frister, eller hvis nogen af disse sager afvises eller hæves. Arresten kan ophæves helt eller delvis på grund af omstændigheder, som er indtruffet efter arrestens foretagelse. Forinden arresten ophæves, skal fogeden så vidt muligt give kreditor lejlighed til at udtale sig.\n",
      "For virksomheder, der i medfør af momslovens § 57, stk. 4, anvender kalenderhalvåret som afgiftsperiode i første og andet halvår af 2020, sammenlægges første halvdel af kalenderåret 2020 med anden halvdel af kalenderåret 2020, således at angivelsesfristen for den samlede periode udløber den 1. marts 2021, medmindre virksomheden angiver et momstilsvar for første halvår 2020 senest den 1. september 2020.\n"
     ]
    }
   ],
   "source": [
    "def dense_retrieval(question, k=3):\n",
    "    \"\"\"\n",
    "    Function that takes a question and returns a list of paragraphs that are most relevant to the question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Encode the input sentence\n",
    "    input_ids = bert_tokenizer.encode(question, return_tensors=\"pt\")  # Encode and add batch dimension\n",
    "    # Pass the input through the model\n",
    "    \n",
    "    with torch.no_grad():  # disable gradient computation for inference\n",
    "        outputs = bert_model(input_ids)\n",
    "\n",
    "    # Extract the CLS token representation\n",
    "    cls_vector = outputs.last_hidden_state[:, 0, :]  # CLS token is at position 0\n",
    "    \n",
    "    # sparse retrieval (cosine similarity)\n",
    "    dense_retrieval = cls_embeddings_tensor_DanskBERT @ torch.transpose(cls_vector, 0, 1)\n",
    "    \n",
    "    # get top k paragraphs\n",
    "    top_k_indices = torch.sort(dense_retrieval, descending=True, dim=0)[1][:k]\n",
    "\n",
    "    return top_k_indices\n",
    "\n",
    "# check if it works using a random question from the dev set\n",
    "random_question = dev_set.iloc[np.random.randint(0, len(dev_set))]['question, str']\n",
    "print(random_question, '\\n')\n",
    "top_k = dense_retrieval(random_question, k=3)\n",
    "for i in top_k:\n",
    "    print(f'{rag_list[i][\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fejl i 6, mangler spørgsmålstegn\n",
    "# 7 er et dårligt spørgsmål\n",
    "# 21 er også lidt dårlig\n",
    "# 35 er ukomplet\n",
    "# 40 og 41 er de samme spørgsmål\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
